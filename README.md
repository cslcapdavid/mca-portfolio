ğŸ“‹ UPDATED STEP-BY-STEP INSTRUCTIONS:
git clone https://github.com/github/mca-portfolio.git
cd mca-portfolio/scripts
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PHASE 1: LOCAL COOKIE EXTRACTION  
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•



1. ğŸ–¥ï¸ RUN LOCALLY (on your machine):
   ```bash
   ```# Save the script as capture_cookies.py```
   python capture_cookies.py
   ```
   

2. ğŸ”‘ MANUAL LOGIN:
   - Browser window will open
   - Login to 1workforce.com manually
   - Complete 2FA (enter code from your phone)
   - Navigate to dashboard/portfolio
   - Press ENTER in terminal when done

3. ğŸ’¾ ENCODE COOKIES:
   ```bash
   # Run this in terminal after step 2
   base64 -i cookies.pkl -o cookies.b64

cat cookies.b64
   ```

4. ğŸ“‹ COPY BASE64 CONTENT:
   ```bash
   # Copy the contents of the base64 file
   cat cookies.b64
   # Copy this output to clipboard
   ```

# Just run this single command
./run_scraper.sh
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PHASE 2: GITHUB REPOSITORY SETUP
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

5. ğŸ”§ ADD GITHUB SECRET:
   - Go to your GitHub repository
   - Click Settings â†’ Secrets and variables â†’ Actions
   - Click "New repository secret"
   - Name: WORKFORCE_COOKIES_B64
   - Value: [paste the base64 content from step 4]
   - Click "Add secret"

6. ğŸ“ ADD OTHER SECRETS (if needed):
   - WORKFORCE_USERNAME (your username)
   - WORKFORCE_PASSWORD (your password)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PHASE 3: GITHUB ACTIONS WORKFLOW
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

7. ğŸ“„ CREATE .github/workflows/scraper.yml:
   ```yaml
   name: MCA Scraper
   on:
     schedule:
       - cron: '0 9 * * 1-5'  # Weekdays 9 AM
     workflow_dispatch:  # Manual trigger
   
   jobs:
     scrape:
       runs-on: ubuntu-latest
       steps:
         - uses: actions/checkout@v3
         
         - name: Setup Python
           uses: actions/setup-python@v4
           with:
             python-version: '3.9'
             
         - name: Install Chrome
           uses: browser-actions/setup-chrome@latest
           
         - name: Install dependencies
           run: |
             pip install selenium beautifulsoup4
             
         - name: Run scraper
           env:
             WORKFORCE_COOKIES_B64: ${{ secrets.WORKFORCE_COOKIES_B64 }}
             WORKFORCE_USERNAME: ${{ secrets.WORKFORCE_USERNAME }}
             WORKFORCE_PASSWORD: ${{ secrets.WORKFORCE_PASSWORD }}
             SCRAPER_MODE: production
           run: python capture_cookies.py
   ```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PHASE 4: TESTING & MAINTENANCE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

8. ğŸ§ª TEST THE WORKFLOW:
   - Go to Actions tab in GitHub
   - Click "MCA Scraper"
   - Click "Run workflow"
   - Monitor the logs

9. ğŸ”„ COOKIE REFRESH (when they expire):
   - Run steps 1-5 again to get fresh cookies
   - Update the WORKFORCE_COOKIES_B64 secret
   - Typical refresh needed every 1-2 weeks

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TROUBLESHOOTING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âŒ If authentication fails:
   - Cookies may have expired
   - Re-run local extraction (steps 1-5)
   - Check GitHub Actions logs for specific errors

âŒ If base64 command not found (Windows):
   ```powershell
   # Use PowerShell instead
   [System.Convert]::ToBase64String([System.IO.File]::ReadAllBytes("cookies.pkl")) | Out-File cookies.b64
   ```

ğŸ” Debug files are saved automatically:
   - debug_auth_failure.html (when auth fails)
   - Check GitHub Actions artifacts
"""
